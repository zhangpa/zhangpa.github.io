<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Patrick Zhang</title>
    <link>https://zhangpa.github.io/post/index.xml</link>
    <description>Recent content in Posts on Patrick Zhang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017</copyright>
    <lastBuildDate>Mon, 06 Mar 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>February 28, 2017 - In-Class Project</title>
      <link>https://zhangpa.github.io/post/february-28-2017-in-class-project/</link>
      <pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zhangpa.github.io/post/february-28-2017-in-class-project/</guid>
      <description>&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ckm_nodes &amp;lt;- read.csv(file = &amp;quot;ckm_nodes.csv&amp;quot;)

head(ckm_nodes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     city adoption_date medical_school attend_meetings medical_journals
## 1 Peoria             1     1920--1929       specialty                9
## 2 Peoria            12          1945+            none                5
## 3 Peoria             8     1935--1939         general                7
## 4 Peoria             9     1940--1944         general                6
## 5 Peoria             9     1935--1939         general                4
## 6 Peoria            10     1930--1934            none                7
##   free_time_with discuss_medicine_socially club_with_drs
## 1    non-doctors                        no            no
## 2        doctors                       yes            no
## 3        doctors                        no            no
## 4    non-doctors                        no            no
## 5    non-doctors                       yes            no
## 6          split                       yes            no
##   drs_among_three_best_friends practicing_here office_visits_per_week
## 1                            0       20+ years               101--150
## 2                            3         1- year                76--100
## 3                            2    10--20 years                76--100
## 4                            0     5--10 years                 51--75
## 5                            1    10--20 years                 51--75
## 6                            0    10--20 years               101--150
##       proximity_to_other_drs    specialty
## 1     in_building_and_office pediatrician
## 2     in_building_and_office           GP
## 3 in_building_but_not_office    internist
## 4     in_building_and_office           GP
## 5 in_building_but_not_office           GP
## 6     in_building_and_office    internist&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(ckm_nodes)[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 246&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(ckm_nodes)[2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 13&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;colnames(ckm_nodes)[1:2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;city&amp;quot;          &amp;quot;adoption_date&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# install.packages(&amp;quot;plyr&amp;quot;)
library(&amp;#39;plyr&amp;#39;)
names(which.max(table(ckm_nodes$adoption_date)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Inf&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;count(ckm_nodes, &amp;#39;adoption_date&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    adoption_date freq
## 1              1   11
## 2              2    9
## 3              3    9
## 4              4   11
## 5              5   11
## 6              6   11
## 7              7   13
## 8              8    7
## 9              9    4
## 10            10    1
## 11            11    5
## 12            12    3
## 13            13    3
## 14            14    4
## 15            15    4
## 16            16    2
## 17            17    1
## 18           Inf   16
## 19            NA  121&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Only include rows in which the adoption date is not NA
cleaned_nodes &amp;lt;- ckm_nodes[which(!is.na(ckm_nodes$adoption_date)),]

dim(cleaned_nodes)[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 125&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(cleaned_nodes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     city adoption_date medical_school attend_meetings medical_journals
## 1 Peoria             1     1920--1929       specialty                9
## 2 Peoria            12          1945+            none                5
## 3 Peoria             8     1935--1939         general                7
## 4 Peoria             9     1940--1944         general                6
## 5 Peoria             9     1935--1939         general                4
## 6 Peoria            10     1930--1934            none                7
##   free_time_with discuss_medicine_socially club_with_drs
## 1    non-doctors                        no            no
## 2        doctors                       yes            no
## 3        doctors                        no            no
## 4    non-doctors                        no            no
## 5    non-doctors                       yes            no
## 6          split                       yes            no
##   drs_among_three_best_friends practicing_here office_visits_per_week
## 1                            0       20+ years               101--150
## 2                            3         1- year                76--100
## 3                            2    10--20 years                76--100
## 4                            0     5--10 years                 51--75
## 5                            1    10--20 years                 51--75
## 6                            0    10--20 years               101--150
##       proximity_to_other_drs    specialty
## 1     in_building_and_office pediatrician
## 2     in_building_and_office           GP
## 3 in_building_but_not_office    internist
## 4     in_building_and_office           GP
## 5 in_building_but_not_office           GP
## 6     in_building_and_office    internist&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;adopters &amp;lt;- function(month, not.yet = FALSE) {
  # Create vector of logicals with length equalling the number of rows in cleaned_nodes
  vec &amp;lt;- vector(mode = &amp;quot;logical&amp;quot;, length = dim(cleaned_nodes)[1])
  if (not.yet == FALSE) {
    # For each row (doctor) in the cleaned data
    for (i in 1:dim(cleaned_nodes)[1]) {
      # True/False if adopted during month
      if (cleaned_nodes$adoption_date[i] == month) {
        vec[i] = TRUE
      } else {
        vec[i] = FALSE
      } 
    }
  } else {
    for (i in 1:dim(cleaned_nodes)[1]) {
      # True/False if adopted after month or never adopted
      if (cleaned_nodes$adoption_date[i] &amp;gt; month || is.infinite(cleaned_nodes$adoption_date[i])) {
        vec[i] = TRUE
      } else {
        vec[i] = FALSE
      } 
    }
  }
  return(vec)
}
length(which(adopters(2)==TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 9&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;length(which(adopters(14, TRUE)==TRUE))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 23&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ckm_network = read.table(&amp;quot;ckm_network.dat&amp;quot;)
# Indices for which the adoption date is not NA
keep &amp;lt;- which(!is.na(ckm_nodes$adoption_date))
# Data set including only rows and columns with kept indices
cleaned_network &amp;lt;- ckm_network[keep,]
cleaned_network &amp;lt;- cleaned_network[,keep]

dim(cleaned_network)[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 125&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(cleaned_network)[2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 125&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(cleaned_network)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20
## 1  0  0  0  0  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0
## 2  0  0  0  0  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0
## 3  0  0  0  0  0  0  0  0  1   0   0   0   0   1   0   1   0   0   0   1
## 4  0  0  0  0  0  0  1  0  0   0   0   0   0   0   0   0   0   0   0   0
## 5  0  0  0  0  0  0  0  0  0   1   0   1   0   0   1   0   0   0   0   0
## 6  0  0  0  0  0  0  0  0  0   0   0   0   0   0   0   0   0   0   0   0
##   V21 V22 V23 V24 V25 V26 V27 V28 V29 V30 V31 V32 V33 V34 V35 V36 V37 V38
## 1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## 2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## 3   0   0   0   0   0   0   0   0   1   0   1   0   1   0   1   0   1   0
## 4   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   1
## 5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## 6   0   0   0   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0
##   V39 V58 V70 V72 V73 V74 V75 V76 V77 V78 V79 V80 V81 V82 V91 V92 V93 V94
## 1   0   1   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0
## 2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## 3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## 4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1
## 5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0
## 6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1
##   V95 V96 V97 V98 V105 V108 V119 V121 V122 V123 V124 V125 V126 V127 V128
## 1   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0
## 2   0   0   0   1    0    0    0    0    0    0    0    0    0    0    0
## 3   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0
## 4   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0
## 5   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0
## 6   0   0   0   0    0    0    0    0    0    0    0    0    0    0    0
##   V129 V130 V131 V132 V133 V134 V135 V136 V137 V151 V152 V153 V154 V155
## 1    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 2    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 3    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 4    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 5    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 6    0    0    0    0    0    0    0    0    0    0    0    0    0    0
##   V156 V168 V169 V170 V171 V172 V173 V174 V175 V176 V177 V178 V179 V180
## 1    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 2    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 3    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 4    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 5    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 6    0    0    0    0    0    0    0    0    0    0    0    0    0    0
##   V181 V182 V195 V196 V197 V198 V199 V200 V212 V213 V214 V215 V216 V217
## 1    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 2    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 3    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 4    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 5    0    0    0    0    0    0    0    0    0    0    0    0    0    0
## 6    0    0    0    0    0    0    0    0    0    0    0    0    0    0
##   V218 V219 V220 V221 V222 V223 V224 V225 V226 V227 V229 V241
## 1    0    0    0    0    0    0    0    0    0    0    0    0
## 2    0    0    0    0    0    0    0    0    0    0    0    0
## 3    0    0    0    0    0    0    0    0    0    0    0    0
## 4    0    0    0    0    0    0    0    0    0    0    0    0
## 5    0    0    0    0    0    0    0    0    0    0    0    0
## 6    0    0    0    0    0    0    0    0    0    0    0    0&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Sums each row of cleaned_network --&amp;gt; number of contacts for each doctor
contacts &amp;lt;- unname(apply(cleaned_network, 1, sum))

contacts[41]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;PART 2 7a.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;count_peer_pressure &amp;lt;- function(index, month) {
  # Indices for which doctors started prescribing at month or earlier
  prescribe &amp;lt;- which(cleaned_nodes$adoption_date &amp;lt;= month)
  # Table of doctors who adopted before month and their contacts
  docs &amp;lt;- cleaned_network[,prescribe]
  # Counts number of contacts
  peers &amp;lt;- unname(apply(docs, 1, sum))
  # Number of contacts for doctor at index number
  peers[index]
}
count_peer_pressure(37, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;7b.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop_peer_pressure &amp;lt;- function(index, month) {
  if (count_peer_pressure(index, month) == 0) {
    return(NaN)
  } else {
    # Proportion of contacts prescribing by month
    return(count_peer_pressure(index, month) / contacts[index])
  }
}
prop_peer_pressure(37,5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop_peer_pressure(102,14)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NaN&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;8a.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avg_peer_pressure &amp;lt;- function(month) {
  # Index of doctors who adopted at month
  index_month &amp;lt;- which(adopters(month) == TRUE)
  # Proportion of prescribing contacts for those doctors
  prop_month &amp;lt;- sapply(index_month, prop_peer_pressure, month)
  # Takes the average of proportions
  avg_month &amp;lt;- mean(prop_month, na.rm = TRUE)
  
  index_after &amp;lt;- which(adopters(month, TRUE) == TRUE)
  prop_after &amp;lt;- sapply(index_after, prop_peer_pressure, month)
  avg_after &amp;lt;- mean(prop_after, na.rm = TRUE)

  return(c(avg_month, avg_after))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;8b.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;month &amp;lt;- c(1:17)
averages &amp;lt;- sapply(month, avg_peer_pressure)

plot(month, averages[1,], type = &amp;quot;o&amp;quot;, col = &amp;quot;red&amp;quot;, xlab = &amp;quot;Month&amp;quot;, ylab = &amp;quot;Proportion of Prescribing Contacts&amp;quot;)
lines(month, averages[2,], type = &amp;quot;o&amp;quot;, col = &amp;quot;blue&amp;quot;)
legend(1,1, legend = c(&amp;quot;Adopters&amp;quot;, &amp;quot;Non-adopters&amp;quot;), col = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;), lty = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://zhangpa.github.io/post/2017-03-06-february-28-2017-in-class-project_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(month, averages[1,]-averages[2,], type = &amp;quot;o&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://zhangpa.github.io/post/2017-03-06-february-28-2017-in-class-project_files/figure-html/unnamed-chunk-10-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>March 5, 2017 - Pre-Class</title>
      <link>https://zhangpa.github.io/post/march-5-2017-pre-class/</link>
      <pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://zhangpa.github.io/post/march-5-2017-pre-class/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;!-- BLOGDOWN-BODY-BEFORE --&gt;
&lt;!-- /BLOGDOWN-BODY-BEFORE --&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean.jackknife &amp;lt;- function(a_vector) {
  n &amp;lt;- length(a_vector)
  
  # Vector of means using omitted data
  theta.i &amp;lt;- vector(length = n)
  for (i in 1:n) {
    theta.i[i] &amp;lt;- mean(a_vector[-i])
  }
  
  # Calculates variance of mean estimates using omitted data
  variance &amp;lt;- var(theta.i)
  
  # Jackknife estimatation for variance and standard error
  jackknife.variance &amp;lt;- (n-1)^2/n * variance
  jackknife.stderr &amp;lt;- sqrt(jackknife.variance)
  return(jackknife.stderr)
}

some_normals &amp;lt;- rnorm(100,mean=7,sd=5)
mean(some_normals)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 7.780643&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(formula_se_of_mean &amp;lt;- sd(some_normals)/sqrt(length(some_normals)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4345963&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(formula_se_of_mean,mean.jackknife(some_normals))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Jackknife Estimator</title>
      <link>https://zhangpa.github.io/post/jackknife_function_R/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zhangpa.github.io/post/jackknife_function_R/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;!-- BLOGDOWN-BODY-BEFORE --&gt;
&lt;!-- /BLOGDOWN-BODY-BEFORE --&gt;
&lt;div id=&#34;jackknife-for-gamma-parameters&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Jackknife for Gamma Parameters&lt;/h2&gt;
&lt;p&gt;Recall our friend the method of moments estimator:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gamma.est &amp;lt;- function(the_data) {
  m &amp;lt;- mean(the_data)
  v &amp;lt;- var(the_data)
  a &amp;lt;- m^2/v
  s &amp;lt;- v/m
  return(c(a=a,s=s))
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;jackknife-for-gamma-parameters-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Jackknife for Gamma Parameters Function&lt;/h3&gt;
&lt;p&gt;Write a function called &lt;code&gt;gamma.jackknife&lt;/code&gt; that takes argument &lt;code&gt;a_vector&lt;/code&gt; and returns jackknife standard error estimates on the gamma parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gamma.jackknife &amp;lt;- function(a_vector) {
  n &amp;lt;- length(a_vector)
  
  # Matrix of gamma estimates using omitted data
  theta.i &amp;lt;- matrix(nrow =n, ncol = 2)
  for (row in 1:n) {
    theta.i[row,] &amp;lt;- gamma.est(a_vector[-row])
  }
  
  # Calculates variance of estimates using omitted data
  variance &amp;lt;- apply(theta.i, 2, var)
  
  # Jackknife estimatation for variance and standard error
  jackknife.variance &amp;lt;- (n-1)^2/n * variance
  jackknife.stderrs &amp;lt;- sqrt(jackknife.variance)
  return(jackknife.stderrs)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;jackknife-for-gamma-parameters-example&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Jackknife for Gamma Parameters Example&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;input &amp;lt;- rgamma(1000, shape=0.1, scale=10)
gamma.est(input)
gamma.jackknife(input)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;jackknife-for-linear-regression-coefficients&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Jackknife for linear regression coefficients&lt;/h2&gt;
&lt;p&gt;Write a function called &lt;code&gt;jackknife.lm&lt;/code&gt; that takes arguments &lt;code&gt;df&lt;/code&gt;, &lt;code&gt;formula&lt;/code&gt; and &lt;code&gt;p&lt;/code&gt; and returns jackknife standard error estimates on the coefficients of a linear regression model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;jackknife.lm &amp;lt;- function(df,formula,p) {
  n &amp;lt;- nrow(df)
  formula &amp;lt;- as.formula(formula)
  
  # Matrix of coefficients using omitted data
  theta.i &amp;lt;- matrix(nrow = n, ncol = p)
  for (row in 1:n) {
    theta.i[row,] &amp;lt;- lm(formula, data = df[-row,])$coefficients
  }
  
  # Calculates variance of estimates using omitted data
  variance &amp;lt;- apply(theta.i, 2, var)
  
  # Jackknife estimatation for variance and standard error
  jackknife.variance &amp;lt;- (n-1)^2/n * variance
  jackknife.stderr &amp;lt;- sqrt(jackknife.variance)
  return(jackknife.stderr)
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;jackknife-for-linear-regression-coefficients-example&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Jackknife for linear regression coefficients Example&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;output &amp;lt;- 1.2 + 0.6*input +  rnorm(1000, 0, 2.1)
data &amp;lt;- data.frame(output,input)
my.lm &amp;lt;- lm(output~input, data=data)
# coefficients(my.lm)
# &amp;quot;Official&amp;quot; standard errors
sqrt(diag(vcov(my.lm)))
# Jackknife standard errors
jackknife.lm(df=data,formula=&amp;quot;output~input&amp;quot;,p=2)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;refactoring-the-jackknife&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Refactoring the Jackknife&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Omitting one point or row is a common sub-task&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The general pattern:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;figure out the size of the data
for each case
   omit that case
   repeat some estimation and get a vector of numbers
take variances across cases
scale up variances
take the square roots&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Refactor by extracting the common “omit one” operation&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Refactor by defining a general “jackknife” operation&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;the-common-operation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Common Operation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Problem&lt;/em&gt;: Omit one particular data point from a larger structure&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Difficulty&lt;/em&gt;: Do we need a comma in the index or not?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Solution&lt;/em&gt;: Works for vectors, lists, 1D and 2D arrays, matrices, data frames:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;goal&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Goal:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Make the function select the correct dimensions
&lt;ul&gt;
&lt;li&gt;length for a 1d object&lt;/li&gt;
&lt;li&gt;number of rows for 2d&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Write a function &lt;code&gt;omit.case&lt;/code&gt; that omits a point given the data and returns the data minus that point. Make sure it can handle higher dimensions.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;      omit.case &amp;lt;- function(the_data,omitted_point) {
        # Dim of vector is NULL ==&amp;gt; dim(1:4)
        # Dim of 1D array is vector with length 1 ==&amp;gt; dim(array(1:4), c(2,2)) 
        if (length(dim(the_data) == 1 || is.null(dim(the_data)))) {
          return(the_data[-omitted_point])
        } else {
          return(the_data[-omitted_point,])
        }
        
      }&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;Write a function &lt;code&gt;omit_and_est&lt;/code&gt; that takes the data with an omitted point and returns whatever function your estimator does.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;jackknife &amp;lt;- function(estimator,the_data) {
  # Define n to be lenth or number of rows here
  if (length(dim(the_data)==1) || is.null(dim(the_data))) {
    n &amp;lt;- length(the_data)
  } else {
    n &amp;lt;- nrow(the_data)
  }
  
  omit_and_est &amp;lt;- function(omit) {
    estimator(omit.case(the_data, omit))
  }
  
  jackknife.ests &amp;lt;- matrix(sapply(1:n, omit_and_est), ncol=n)
  var.of.reestimates &amp;lt;- apply(jackknife.ests,1,var)
  jackknife.var &amp;lt;- ((n-1)^2/n)* var.of.reestimates
  jackknife.stderr &amp;lt;- sqrt(jackknife.var)
  return(jackknife.stderr)
}&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;div id=&#34;it-works&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;It works&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;some_normals &amp;lt;- rnorm(100,mean=7,sd=5)
mean.jackknife &amp;lt;- function(a_vector) {
  n &amp;lt;- length(a_vector)
  theta.i &amp;lt;- vector(length = n)
  for (i in 1:n) {
    theta.i[i] &amp;lt;- mean(a_vector[-i])
  }
  variance &amp;lt;- var(theta.i)
  jackknife.variance &amp;lt;- (n-1)^2/n * variance
  jackknife.stderr &amp;lt;- sqrt(jackknife.variance)
  return(jackknife.stderr)
}
# jackknife(estimator=mean,the_data=some_normals)
all.equal(jackknife(estimator=mean,the_data=some_normals),
          mean.jackknife(some_normals))&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(jackknife(estimator=gamma.est,the_data=data$input),
          gamma.jackknife(data$input))&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all.equal(jackknife(estimator=gamma.est,the_data=data$input),
          gamma.jackknife(data$input), check.names=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;est.coefs &amp;lt;- function(the_data) {
  return(lm(output~input,data=the_data)$coefficients)
}
# est.coefs(data)
all.equal(est.coefs(data), coefficients(my.lm))&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# jackknife(estimator=est.coefs,the_data=data)
all.equal(jackknife(estimator=est.coefs,the_data=data),
          jackknife.lm(df=data,formula=&amp;quot;output~input&amp;quot;,p=2))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;further-refactoring-of-jackknife&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Further Refactoring of jackknife()&lt;/h2&gt;
&lt;p&gt;The code for &lt;code&gt;jackknife()&lt;/code&gt; is still a bit clunky: - Ugly &lt;code&gt;if-else&lt;/code&gt; for finding &lt;code&gt;n&lt;/code&gt; - Bit at the end for scaling variances down to standard errors&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;write a function that calculates the &lt;code&gt;n&lt;/code&gt; needed for the above code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  data_size &amp;lt;- function(the_data) {
    if (length(dim(the_data)==1) || is.null(dim(the_data))) {
      return(length(the_data))
    } else {
      return(nrow(the_data))
    }
  }&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Write a funcrion that calculate the variance of all the estimates and returns the standard error&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;scale_and_sqrt_vars &amp;lt;- function(jackknife.ests,n) {
  var.of.reestimates &amp;lt;- apply(jackknife.ests,1,var)
  jackknife.var &amp;lt;- ((n-1)^2/n)* var.of.reestimates
  jackknife.stderr &amp;lt;- sqrt(jackknife.var)
  return(jackknife.stderr)
}&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;now-invoke-those-functions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Now invoke those functions&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;jackknife &amp;lt;- function(estimator,the_data) {
  n &amp;lt;- data_size(the_data)
  omit_and_est &amp;lt;- function(omit) {
    estimator(omit.case(the_data,omit))
  }
  jackknife.ests &amp;lt;- matrix(sapply(1:n, omit_and_est), ncol=n)
  return(scale_and_sqrt_vars(jackknife.ests,n))
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Simulations Pre-Class Project</title>
      <link>https://zhangpa.github.io/post/2017-03-13-march-14-2017-pre-class/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zhangpa.github.io/post/2017-03-13-march-14-2017-pre-class/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;!-- BLOGDOWN-BODY-BEFORE --&gt;
&lt;!-- /BLOGDOWN-BODY-BEFORE --&gt;
&lt;p&gt;Suppose you have a bankroll of $1000 and make bets of $100 on a fair game. By simulating the outcome directly for at most 5000 iterations of the game (or hands), estimate:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;the probability that you have “busted” (lost all your money) by the time you have placed your one hundredth bet.&lt;/li&gt;
&lt;li&gt;the probability that you have busted by the time you have placed your five hundredth bet by simulating the outcome directly.&lt;/li&gt;
&lt;li&gt;the mean time you go bust, given that you go bust within the first 5000 hands.&lt;/li&gt;
&lt;li&gt;the mean and variance of your bankroll after 100 hands (including busts).&lt;/li&gt;
&lt;li&gt;the mean and variance of your bankroll after 500 hands (including busts).&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This function simulates the game and winnings for a specified number of turns
# Inputs: number of hand/games, probability of winning, bankroll, bet/wager, if markov, and increment value
# Output: vector of total money and number of hands/games
sim_game &amp;lt;- function(hands, p = 0.5, inc = 0.01, bankroll = 1000, bets = 100, markov = FALSE) {
  total &amp;lt;- bankroll
  prob &amp;lt;- p
  
  # For each hand/game
  for (i in 1:hands) {
    # Add/subtract wager from total
    outcome &amp;lt;- rbinom(1,1,prob)
    total &amp;lt;- total + (2*bets*outcome - bets)
    # If not Markov, going bust is possible 
    # Return 0 and the index that the player went bust
    if (!markov) {
      if (total == 0) {
        return(c(0,i))
      }
    # If Markov, increment probability accordingly
    } else {
      if (outcome == 1 &amp;amp; prob + inc &amp;lt;= 1) {
        prob &amp;lt;- prob + inc
      } else if (outcome == 0) {
        prob &amp;lt;- p
      }
    }
  }
  return(c(total, hands))
}

# This function calculates the probabilities and means asked in the first two questions.
# Inputs: two values for number of hands/games, probability of winning, and number of repetitions
calc_bust &amp;lt;- function(hands, hands2, prob = 0.5, rep = 5000) {
  # Simulates games for part a and calculates probability of bust
  sim_a &amp;lt;- replicate(rep, sim_game(hands, p = prob))
  prob_a &amp;lt;- length(which(sim_a[1,] == 0))/rep
  # Simulates games for part b and calculates probability of bust
  sim_b &amp;lt;- replicate(rep, sim_game(hands2, p = prob))
  prob_b &amp;lt;- length(which(sim_b[1,] == 0))/rep
  # Simulates games for part c and calculates the average number of hands to bust
  sim_c &amp;lt;- replicate(rep, sim_game(rep, p = prob))
  busted &amp;lt;- which(sim_c[1,] == 0)
  mean_bust &amp;lt;- mean(sim_c[2,busted])
  # Calculates mean and variance for the situations in parts a and b
  mv_d &amp;lt;- c(mean(sim_a[2,]), var(sim_a[2,]))
  mv_e &amp;lt;- c(mean(sim_b[2,]), var(sim_b[2,]))
  return(c(prob_a, prob_b, mean_bust, mv_d, mv_e))
}

sol &amp;lt;- calc_bust(100, 500)
sol&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]     0.3094     0.6470   534.8282    85.4852   642.2354   270.7660
## [7] 38344.7966&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Repeat the previous problem with betting on black in American roulette, where the probability of winning on any spin is 18/38 for an even payout.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sol2 &amp;lt;- calc_bust(100, 500, prob = 18/38)
sol2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]     0.5056     0.9130   188.9040    76.0452   852.0444   160.6332
## [7] 21910.2331&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Suppose you have a game where the probability of winning on your first hand is 48%; each time you win, that probability goes up by one percentage point for the next game (to a maximum of 100%, where it must stay), and each time you lose, it goes back down to 48%. Assume you cannot go bust and that the size of your wager is a constant $100.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Is this a fair game? Simulate one hundred thousand sequential hands to determine the size of your return. Then repeat this simulation 99 more times to get a range of values to calculate the expectation.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;markov_sim &amp;lt;- replicate(100, sim_game(10000, p = 0.48, markov = TRUE))
markov_exp &amp;lt;- mean(markov_sim[1,])
markov_exp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -20876&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Repeat this process but change the starting probability to a new value within 2% either way. Get the expected return after 100 repetitions. Keep exploring until you have a return value that is as fair as you can make it. Can you do this automatically?&lt;/li&gt;
&lt;li&gt;Repeat again, keeping the initial probability at 48%, but this time change the probability increment to a value different from 1%. Get the expected return after 100 repetitions. Keep changing this value until you have a return value that is as fair as you can make it.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# This function determines the fairest starting probability or increment value
# Input: start: TRUE - calculate starting p, FALSE - calculate increment value
# Output: vector of value (index 1) and 100 returns/total money remaining (index 2:101)
fair_markov &amp;lt;- function(start = FALSE) {
  incrm &amp;lt;- 0.01
  prob &amp;lt;- 0.48
  # Smallest difference between starting money and return after playing (absolute value)
  smallest_diff &amp;lt;- abs(1000 - markov_exp)
  repeat {
    # If finding increment, increase value each repetition
    if (!start) {
      incrm &amp;lt;- incrm + 0.001
      sim &amp;lt;- replicate(100, sim_game(10000, p = prob, inc = incrm, markov = TRUE))
      diff &amp;lt;- abs(1000-mean(sim[1,]))
      # If new difference is smaller than smallest_diff, update value
      if (diff &amp;lt; smallest_diff) {
        smallest_diff &amp;lt;- diff
      # If new difference is greater, stop repetition and output
      } else {
        return(c(incrm, sim[1,]))
      }
    # If finding starting p, repeat process above except with increasing prob
    } else {
      prob &amp;lt;- prob + 0.001
      sim &amp;lt;- replicate(100, sim_game(10000, p = prob, markov = TRUE))
      diff &amp;lt;- abs(1000-mean(sim[1,]))
      if (diff &amp;lt; smallest_diff) {
        smallest_diff &amp;lt;- diff
      } else {
        return(c(prob, sim[1,]))
      }
    }
  }
}
start_value &amp;lt;- fair_markov(start = TRUE)
inc_value &amp;lt;- fair_markov()

c(start_value[1], mean(start_value[-1]), var(start_value[-1]))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4.910000e-01 7.290000e+03 1.063849e+08&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;c(inc_value[1], mean(inc_value[-1]), var(inc_value[-1]))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.800000e-02 2.484000e+03 1.452696e+08&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the last two examples in the previous question, you calculated a mean value. Because you saved these final results in a vector, use the bootstrap to estimate the variance of the return in each case for your final answer. Once you have these results, which game has the smaller variance in returns?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;boot1 &amp;lt;- start_value[-1]
boot2 &amp;lt;- inc_value[-1]
# Sample both vectors with replacement and take the bootstrap variance
var1 &amp;lt;- var(sample(boot1, replace = TRUE))
var2 &amp;lt;- var(sample(boot2, replace = TRUE))
c(var1, var2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  96557071 185714630&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
